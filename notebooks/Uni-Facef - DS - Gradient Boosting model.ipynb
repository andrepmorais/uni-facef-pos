{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Uni-Facef - Data Science - Parte 1 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Neste notebook vamos criar um modelo de classificação usando o algorítmo Gradient Boosting. Vamos fazer o treinamento do modelo, medir sua acurácia (nível de acerto) e fazer a persistência (serialização do objeto em arquivo)\n",
    "\n",
    "    Vamos utilizar a biblioteca Pandas e Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING\n",
    "\n",
    "    Trata-se de um Método Ensemble, onde ocorre a predição de múltiplos algoritmos base de árvore de regressão em um único classificador. Esse algoritmo implementa as seguintes técnicas:\n",
    "\n",
    "\n",
    "#### Boosting\n",
    "\t\n",
    "    Realiza a classificação a partir de um sistema de peso, constituído a partir do resultado de classificação de cada algoritmo base.\n",
    "\n",
    "#### Gradient Descent\n",
    "\t\n",
    "    Otimização iterativa para encontrar o mínimo de uma função de custo, a Cost function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo o dataset em Dataframe Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lendo o dataset em csv e criando um Dataframe Pandas\n",
    "df = pd.read_csv(\"gradient_boosting_training.csv\", delimiter=\"|\")\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a distribuição entre as classes (variável target)\n",
    "\n",
    "É importante termos as classes bem balanceadas para que o algorítmo aprenda a relação desses dados de forma mais assertiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby('propenso').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo um pré-processamento dos dados\n",
    "\n",
    "Em sua grande maioria das vezes o trabalho de pré-processamento é pesado, pois podem haver muitos campos nulos, com ruídos (outliers), variáveis categóricas da qual muitos algorítimos não trabalham, etc. E há muitas técnicas para que cada caso possa ser tratado.\n",
    "\n",
    "Nesse exemplo, consideramos que fizemos um trabalho de processamento e padronização previamente pelo Spark teremos um menor esforço de tratamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tratando dados missing no vlrmediocompra\n",
    "df['vlrmediocompra'] = df['vlrmediocompra'].replace(np.NaN, 0)\n",
    "\n",
    "# Vamos usar a técnica de colocar média da massa para a idade\n",
    "df['idade'].fillna(df['idade'].mean(), inplace=True)\n",
    "\n",
    "# Vamos usar a média da massa para a recencia também\n",
    "df['recencia'].fillna(df['recencia'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando a variável target (resposta) das variáveis preditoras\n",
    "\n",
    "- X - Variáveis preditoras\n",
    "- Y - Variável target ou resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col not in ['id','propenso', 'recencia', 'scorecompra']]\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Arrays:\n",
    " - X - Variáveis preditoras\n",
    " - Y - Variável target ou resposta\n",
    "\"\"\"\n",
    "X = df[cols].values\n",
    "Y = df.propenso.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colocando os valores das variável preditoras numa mesma escala\n",
    "\n",
    "Observe que os valores numéricos não estão no mesma escala e muitos algorítimos terão melhor performance fazendo essa normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para isso usaremos o método \"scale\" do módulo \"preprocessing\" do \"sklearn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X = scale(X)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando os dados de treino dos dados de teste\n",
    "\n",
    "Para isso usaremos o método \"train_test_split\" do módulo \"model_selection\" do \"sklearn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Percentual da massa para treino\n",
    "validation_size = 0.30\n",
    "\n",
    "\"\"\"\n",
    "Retorna 4 arrays diferentes:\n",
    "\n",
    "X_Train - Variáveis preditoras para o treinamento do modelo\n",
    "X_Test - Variáveis preditoras para o teste do modelo\n",
    "\n",
    "Y_Train - Variável target ou resposta para treinamento do modelo\n",
    "Y_Test - Variável target ou resposta usada para validação do modelo\n",
    "\"\"\"\n",
    "\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size = validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando uma instancia do algoritmo Classificador\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(\n",
    "    n_estimators=50,\n",
    "    learning_rate=1, \n",
    "    min_samples_split=3, \n",
    "    min_samples_leaf=2)\n",
    "\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e persistência do modelo\n",
    "\n",
    "Treina o modelo através do método \"fit\" do Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.fit(X_Train, Y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persistirá o modelo treinado em arquivo\n",
    "\n",
    "Para isso usaremos o módulo \"pickle\" que fará a serialização do objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"gradient_boosting_model_pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo a predição da variável resposta esperada\n",
    "\n",
    "Podemos utilizar o modelo em memória ou fazer o \"load\" do modelo persistido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_serial = pickle.load(open(\"gradient_boosting_model_pickle.dat\", \"rb\"))\n",
    "\n",
    "model_serial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fazendo previsão com variaveis preditoras de teste através do método \"predict\" do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_Test)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.predict_proba(X_Test)[:,1]\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame(prediction, columns=['propenso'])\n",
    "df_score = pd.DataFrame(score, columns=['score'])\n",
    "\n",
    "df_result = pd.merge(df_predict, df_score, how = 'left', left_index = True, right_index = True)\n",
    "\n",
    "df_result.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print (accuracy_score(Y_Test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print (\"Confusion Matrix:\\n\")\n",
    "print (confusion_matrix(Y_Test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (\"Classification Report:\\n\")\n",
    "print (classification_report(Y_Test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevância das principais variáveis preditoras para o Modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_serial.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Variáveis mais importantes\")\n",
    "\n",
    "plt.bar(range(X.shape[1]), importances[indices], color=\"b\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Mostrar legenda abaixo do gráfico\n",
    "for i in range(0,len(cols)):\n",
    "    print (str(i)+' - '+ cols[i] +' --> '+ str(model.feature_importances_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a correlação entre as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Aprenda mais sobre \"scikit-learn\": \n",
    "\n",
    "https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
